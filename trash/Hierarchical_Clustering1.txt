import json
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.cluster.hierarchy import linkage, dendrogram, fcluster

output_dir = 'dzivoklu_data'

# Load data
def load_data(location_name):
    try:
        with open(f"{output_dir}/{location_name}_prices.json", 'r', encoding='utf-8') as json_file:
            return json.load(json_file)
    except FileNotFoundError:
        print(f"Data file for {location_name} not found.")
        return None


def extract_prices_and_sizes(data):
    one_time_purchase = [(entry['Price_per_m²'], entry['Price'], entry['m²']) for entry in data['one_time_purchase']]
    return one_time_purchase


# Analyze clusters with Hierarchical Clustering
def analyze_clusters_hierarchical(locations, n_clusters):
    all_one_time_purchase = []
    district_labels = []

    # Load data from each location
    for location in locations:
        location_name = location["name"]
        data = load_data(location_name)
        if data:
            one_time_purchase = extract_prices_and_sizes(data)
            all_one_time_purchase.extend(one_time_purchase)
            district_labels.extend([location_name] * len(one_time_purchase))

    # Convert data into arrays for clustering
    all_one_time_purchase = np.array(all_one_time_purchase)
    prices_per_m2 = all_one_time_purchase[:, 0]  # Price per m²
    sizes = all_one_time_purchase[:, 2]          # Size (m²)
    features = np.column_stack((prices_per_m2, sizes))

    # Perform Hierarchical Clustering
    Z = linkage(features, method='ward')  # Linkage matrix using Ward's method

    # Create dendrogram
    plt.figure(figsize=(12, 8))
    dendrogram(Z, truncate_mode='lastp', p=20, leaf_rotation=45., leaf_font_size=10., show_contracted=True)
    plt.title('Hierarchical Clustering Dendrogram')
    plt.xlabel('Sample Index')
    plt.ylabel('Distance')
    plt.tight_layout()
    plt.show()

    # Assign clusters based on desired number of clusters
    labels = fcluster(Z, t=n_clusters, criterion='maxclust')

    # Combine data into a DataFrame for easier analysis
    combined_data = pd.DataFrame({
        'District': district_labels,
        'Cluster': labels,
        'Size (m²)': sizes,
        'Price per m²': prices_per_m2
    })

    # Cluster composition by district
    cluster_summary = combined_data.groupby(['Cluster', 'District']).size().unstack(fill_value=0)

    # Descriptive statistics for clusters
    cluster_stats = combined_data.groupby('Cluster').agg({
        'Size (m²)': ['mean', 'median', 'std'],
        'Price per m²': ['mean', 'median', 'std']
    })

    # Print and visualize results
    print("Cluster Summary by District:")
    print(cluster_summary)

    print("\nDescriptive Statistics for Each Cluster:")
    print(cluster_stats)

    # Return combined data for further analysis if needed
    return combined_data, Z, cluster_summary


# Plot the cluster composition heatmap
def plot_cluster_composition(cluster_summary):
    # Create the heatmap figure
    plt.figure(figsize=(12, 8))
    sns.heatmap(cluster_summary, cmap="YlGnBu", annot=True, fmt="d", linewidths=.5)
    plt.title("Cluster Composition by District")
    plt.xlabel("District")
    plt.ylabel("Cluster")
    plt.tight_layout()


# Full list of districts with details
locations = [
    {"name": "Centrs", "url": "...", "archive_url": "...", "pages": 158},
    {"name": "Āgenskalns", "url": "...", "archive_url": "...", "pages": 34},
    # Add other districts as necessary
]

# Run the analysis with 4 clusters
n_clusters = 4
combined_data, Z, cluster_summary = analyze_clusters_hierarchical(locations, n_clusters)

# Plot the cluster composition heatmap
plot_cluster_composition(cluster_summary)

# Show the plots
plt.show()
